{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TriageFlow: Incident Triage Demo\n",
    "\n",
    "Multi-agent incident triage with Domino GenAI tracing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Save your API key as a Domino user environment variable:\n",
    "1. **Account Settings** → **User Environment Variables**\n",
    "2. Add `OPENAI_API_KEY` or `ANTHROPIC_API_KEY`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Provider & Vertical\n",
    "\n",
    "Choose your LLM provider and industry vertical for sample incidents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e727ee0cba5a43df99558daeedb6be76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Provider:', options=('openai', 'anthropic'), value='openai')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6c95157a3aa4272bf418820f6cbf84b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Vertical:', options=(('Financial Services', 'financial_services'), ('Healthcare', 'healt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "provider_dropdown = widgets.Dropdown(\n",
    "    options=[\"openai\", \"anthropic\"],\n",
    "    value=\"openai\",\n",
    "    description=\"Provider:\"\n",
    ")\n",
    "\n",
    "vertical_dropdown = widgets.Dropdown(\n",
    "    options=[\n",
    "        (\"Financial Services\", \"financial_services\"),\n",
    "        (\"Healthcare\", \"healthcare\"),\n",
    "        (\"Energy\", \"energy\"),\n",
    "        (\"Public Sector\", \"public_sector\")\n",
    "    ],\n",
    "    value=\"financial_services\",\n",
    "    description=\"Vertical:\"\n",
    ")\n",
    "\n",
    "display(provider_dropdown, vertical_dropdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Configuration\n",
    "\n",
    "All prompts, model settings, and agent parameters are centralized in `config.yaml`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provider: anthropic\n",
      "Model: claude-sonnet-4-20250514\n"
     ]
    }
   ],
   "source": [
    "with open(\"config.yaml\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "provider = provider_dropdown.value\n",
    "model = config[\"models\"][provider]\n",
    "print(f\"Provider: {provider}\\nModel: {model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Client & Auto-Tracing\n",
    "\n",
    "MLflow's `autolog()` automatically captures all LLM calls without additional instrumentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto-tracing enabled for anthropic\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "if provider == \"openai\":\n",
    "    from openai import OpenAI\n",
    "    client = OpenAI()\n",
    "    mlflow.openai.autolog()\n",
    "else:\n",
    "    from anthropic import Anthropic\n",
    "    client = Anthropic()\n",
    "    mlflow.anthropic.autolog()\n",
    "\n",
    "print(f\"Auto-tracing enabled for {provider}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Domino Tracing\n",
    "\n",
    "- `add_tracing`: Decorator for capturing inputs, outputs, and evaluation metrics\n",
    "- `DominoRun`: Context manager for aggregating metrics across multiple traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from domino.agents.tracing import add_tracing\n",
    "from domino.agents.logging import DominoRun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Models, Agents, and Judges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import Incident, IncidentSource\n",
    "from src.agents import classify_incident, assess_impact, match_resources, draft_response\n",
    "from src.judges import judge_classification, judge_response, judge_triage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_evaluator(span) -> dict:\n",
    "    \"\"\"Extract metrics and run LLM judges on pipeline outputs.\"\"\"\n",
    "    outputs = span.outputs or {}\n",
    "    inputs = span.inputs or {}\n",
    "\n",
    "    if not hasattr(outputs, \"get\"):\n",
    "        return {}\n",
    "\n",
    "    # Get incident from inputs\n",
    "    incident_data = inputs.get(\"incident\", {})\n",
    "    if hasattr(incident_data, \"model_dump\"):\n",
    "        incident_data = incident_data.model_dump()\n",
    "    incident_desc = incident_data.get(\"description\", \"\") if isinstance(incident_data, dict) else \"\"\n",
    "\n",
    "    classification = outputs.get(\"classification\")\n",
    "    impact = outputs.get(\"impact\")\n",
    "    resources = outputs.get(\"resources\")\n",
    "    response = outputs.get(\"response\")\n",
    "\n",
    "    # Convert Pydantic models to dicts\n",
    "    if hasattr(classification, \"model_dump\"):\n",
    "        classification = classification.model_dump()\n",
    "    if hasattr(impact, \"model_dump\"):\n",
    "        impact = impact.model_dump()\n",
    "    if hasattr(resources, \"model_dump\"):\n",
    "        resources = resources.model_dump()\n",
    "    if hasattr(response, \"model_dump\"):\n",
    "        response = response.model_dump()\n",
    "\n",
    "    classification = classification or {}\n",
    "    impact = impact or {}\n",
    "    resources = resources or {}\n",
    "    response = response or {}\n",
    "\n",
    "    primary = resources.get(\"primary_responder\", {})\n",
    "    if hasattr(primary, \"model_dump\"):\n",
    "        primary = primary.model_dump()\n",
    "    primary = primary or {}\n",
    "\n",
    "    # Base metrics\n",
    "    metrics = {\n",
    "        \"classification_confidence\": classification.get(\"confidence\", 0.5),\n",
    "        \"impact_score\": impact.get(\"impact_score\", 5.0),\n",
    "        \"resource_match_score\": primary.get(\"match_score\", 0.5) if isinstance(primary, dict) else 0.5,\n",
    "        \"completeness_score\": response.get(\"completeness_score\", 0.5),\n",
    "    }\n",
    "\n",
    "    # Judge evaluations\n",
    "    metrics[\"classification_judge_score\"] = judge_classification(\n",
    "        client, provider, incident_desc, classification\n",
    "    ).get(\"score\", 3)\n",
    "\n",
    "    comms = response.get(\"communications\", [])\n",
    "    if comms:\n",
    "        comm = comms[0] if isinstance(comms[0], dict) else comms[0].model_dump() if hasattr(comms[0], \"model_dump\") else {}\n",
    "        metrics[\"response_judge_score\"] = judge_response(\n",
    "            client, provider, incident_desc, classification.get(\"urgency\", 3), comm\n",
    "        ).get(\"score\", 3)\n",
    "    else:\n",
    "        metrics[\"response_judge_score\"] = 1\n",
    "\n",
    "    metrics[\"triage_judge_score\"] = judge_triage(\n",
    "        client, provider, incident_desc, classification, impact, resources, response\n",
    "    ).get(\"score\", 3)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Traced Pipeline\n",
    "\n",
    "The `@add_tracing` decorator creates a single trace tree per incident. Each agent runs as a nested span with:\n",
    "- Function inputs and outputs\n",
    "- LLM calls captured via autolog (showing span types like `ChatCompletion`)\n",
    "- Evaluation metrics attached to the trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@add_tracing(name=\"triage_incident\", autolog_frameworks=[provider], evaluator=pipeline_evaluator)\n",
    "def triage_incident(incident: Incident):\n",
    "    \"\"\"Run the 4-agent triage pipeline. Autolog captures all LLM calls with span types.\"\"\"\n",
    "    classification = classify_incident(client, provider, model, incident, config)\n",
    "    impact = assess_impact(client, provider, model, incident, classification, config)\n",
    "    resources = match_resources(client, provider, model, classification, impact, config)\n",
    "    response = draft_response(client, provider, model, incident, classification, impact, resources, config)\n",
    "\n",
    "    return {\n",
    "        \"classification\": classification,\n",
    "        \"impact\": impact,\n",
    "        \"resources\": resources,\n",
    "        \"response\": response\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Sample Incidents\n",
    "\n",
    "Example incidents will be loaded from the vertical selected above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10 incidents from healthcare\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticket_id</th>\n",
       "      <th>description</th>\n",
       "      <th>source</th>\n",
       "      <th>reporter</th>\n",
       "      <th>affected_system</th>\n",
       "      <th>initial_severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HLT-2024-001</td>\n",
       "      <td>Electronic Health Records system unresponsive ...</td>\n",
       "      <td>user_report</td>\n",
       "      <td>ED Charge Nurse</td>\n",
       "      <td>Epic EHR</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HLT-2024-002</td>\n",
       "      <td>Lab results interface failing to transmit crit...</td>\n",
       "      <td>monitoring</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lab Information System</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HLT-2024-003</td>\n",
       "      <td>Patient portal showing incorrect appointment t...</td>\n",
       "      <td>user_report</td>\n",
       "      <td>Patient Services</td>\n",
       "      <td>Patient Portal</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HLT-2024-004</td>\n",
       "      <td>HIPAA audit log showing gaps in access trackin...</td>\n",
       "      <td>automated_scan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Radiology PACS</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HLT-2024-005</td>\n",
       "      <td>Medication dispensing cabinets in ICU reportin...</td>\n",
       "      <td>user_report</td>\n",
       "      <td>ICU Pharmacy</td>\n",
       "      <td>Pyxis MedStation</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HLT-2024-006</td>\n",
       "      <td>Telehealth platform video quality degraded. Pr...</td>\n",
       "      <td>user_report</td>\n",
       "      <td>Telehealth Support</td>\n",
       "      <td>Teladoc Platform</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HLT-2024-007</td>\n",
       "      <td>Billing system rejecting Medicare claims with ...</td>\n",
       "      <td>monitoring</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Claims Processing System</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HLT-2024-008</td>\n",
       "      <td>Surgical scheduling system double-booked OR-3 ...</td>\n",
       "      <td>user_report</td>\n",
       "      <td>Surgery Coordinator</td>\n",
       "      <td>Surgical Scheduling</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HLT-2024-009</td>\n",
       "      <td>Blood bank inventory system not syncing with r...</td>\n",
       "      <td>monitoring</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Blood Bank Management</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HLT-2024-010</td>\n",
       "      <td>Ransomware indicators detected on imaging work...</td>\n",
       "      <td>automated_scan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Radiology Workstation</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ticket_id                                        description  \\\n",
       "0  HLT-2024-001  Electronic Health Records system unresponsive ...   \n",
       "1  HLT-2024-002  Lab results interface failing to transmit crit...   \n",
       "2  HLT-2024-003  Patient portal showing incorrect appointment t...   \n",
       "3  HLT-2024-004  HIPAA audit log showing gaps in access trackin...   \n",
       "4  HLT-2024-005  Medication dispensing cabinets in ICU reportin...   \n",
       "5  HLT-2024-006  Telehealth platform video quality degraded. Pr...   \n",
       "6  HLT-2024-007  Billing system rejecting Medicare claims with ...   \n",
       "7  HLT-2024-008  Surgical scheduling system double-booked OR-3 ...   \n",
       "8  HLT-2024-009  Blood bank inventory system not syncing with r...   \n",
       "9  HLT-2024-010  Ransomware indicators detected on imaging work...   \n",
       "\n",
       "           source             reporter           affected_system  \\\n",
       "0     user_report      ED Charge Nurse                  Epic EHR   \n",
       "1      monitoring                  NaN    Lab Information System   \n",
       "2     user_report     Patient Services            Patient Portal   \n",
       "3  automated_scan                  NaN            Radiology PACS   \n",
       "4     user_report         ICU Pharmacy          Pyxis MedStation   \n",
       "5     user_report   Telehealth Support          Teladoc Platform   \n",
       "6      monitoring                  NaN  Claims Processing System   \n",
       "7     user_report  Surgery Coordinator       Surgical Scheduling   \n",
       "8      monitoring                  NaN     Blood Bank Management   \n",
       "9  automated_scan                  NaN     Radiology Workstation   \n",
       "\n",
       "   initial_severity  \n",
       "0                 5  \n",
       "1                 5  \n",
       "2                 3  \n",
       "3                 4  \n",
       "4                 4  \n",
       "5                 3  \n",
       "6                 3  \n",
       "7                 4  \n",
       "8                 4  \n",
       "9                 5  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertical = vertical_dropdown.value\n",
    "df = pd.read_csv(f\"example-data/{vertical}.csv\")\n",
    "print(f\"Loaded {len(df)} incidents from {vertical}\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10 incidents\n"
     ]
    }
   ],
   "source": [
    "def row_to_incident(row) -> Incident:\n",
    "    return Incident(\n",
    "        ticket_id=row[\"ticket_id\"],\n",
    "        description=row[\"description\"],\n",
    "        source=IncidentSource(row[\"source\"]),\n",
    "        reporter=row[\"reporter\"] if pd.notna(row[\"reporter\"]) else None,\n",
    "        affected_system=row[\"affected_system\"] if pd.notna(row[\"affected_system\"]) else None,\n",
    "        initial_severity=int(row[\"initial_severity\"]) if pd.notna(row[\"initial_severity\"]) else None\n",
    "    )\n",
    "\n",
    "incidents = [row_to_incident(row) for _, row in df.iterrows()]\n",
    "print(f\"Loaded {len(incidents)} incidents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Triage Pipeline\n",
    "\n",
    "`DominoRun` aggregates metrics across all traces in the batch via `custom_summary_metrics`. Supported aggregations: `mean`, `median`, `stdev`, `min`, `max`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: tracing-andrea_lowe\n",
      "Run: healthcare-andrea_lowe-20251201-205009\n"
     ]
    }
   ],
   "source": [
    "# Experiment and run naming\n",
    "username = os.environ.get(\"DOMINO_USER_NAME\", os.environ.get(\"USER\", \"demo_user\"))\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "experiment_name = f\"tracing-{username}\"\n",
    "run_name = f\"{vertical}-{username}-{timestamp}\"\n",
    "\n",
    "aggregated_metrics = [\n",
    "    # Base metrics\n",
    "    (\"classification_confidence\", \"mean\"),\n",
    "    (\"impact_score\", \"median\"),\n",
    "    (\"resource_match_score\", \"mean\"),\n",
    "    (\"completeness_score\", \"mean\"),\n",
    "    # Judge scores\n",
    "    (\"classification_judge_score\", \"mean\"),\n",
    "    (\"response_judge_score\", \"mean\"),\n",
    "    (\"triage_judge_score\", \"mean\"),\n",
    "]\n",
    "\n",
    "print(f\"Experiment: {experiment_name}\")\n",
    "print(f\"Run: {run_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing HLT-2024-001...\n",
      "  → infrastructure | Urgency: 5 | Impact: 8.0\n",
      "Processing HLT-2024-002...\n",
      "  → infrastructure | Urgency: 5 | Impact: 8.5\n",
      "Processing HLT-2024-003...\n",
      "  → operational | Urgency: 3 | Impact: 5.0\n",
      "Processing HLT-2024-004...\n",
      "  → compliance | Urgency: 4 | Impact: 7.0\n",
      "Processing HLT-2024-005...\n",
      "  → infrastructure | Urgency: 4 | Impact: 7.0\n",
      "Processing HLT-2024-006...\n",
      "  → performance | Urgency: 4 | Impact: 7.0\n",
      "Processing HLT-2024-007...\n",
      "  → operational | Urgency: 3 | Impact: 6.0\n",
      "Processing HLT-2024-008...\n",
      "  → data_integrity | Urgency: 4 | Impact: 6.0\n",
      "Processing HLT-2024-009...\n"
     ]
    }
   ],
   "source": [
    "# Set MLflow experiment\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "results = []\n",
    "\n",
    "with DominoRun(agent_config_path=\"config.yaml\", custom_summary_metrics=aggregated_metrics) as run:\n",
    "    # Set run name via MLflow\n",
    "    mlflow.set_tag(\"mlflow.runName\", run_name)\n",
    "    \n",
    "    for incident in incidents:\n",
    "        print(f\"Processing {incident.ticket_id}...\")\n",
    "        \n",
    "        result = triage_incident(incident)\n",
    "        \n",
    "        results.append({\n",
    "            \"ticket_id\": incident.ticket_id,\n",
    "            **result\n",
    "        })\n",
    "        print(f\"  → {result['classification'].category.value} | Urgency: {result['classification'].urgency} | Impact: {result['impact'].impact_score}\")\n",
    "\n",
    "print(f\"\\nProcessed {len(results)} incidents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame([{\n",
    "    \"Ticket\": r[\"ticket_id\"],\n",
    "    \"Category\": r[\"classification\"].category.value,\n",
    "    \"Urgency\": r[\"classification\"].urgency,\n",
    "    \"Impact\": r[\"impact\"].impact_score,\n",
    "    \"Responder\": r[\"resources\"].primary_responder.name,\n",
    "    \"SLA Met\": r[\"resources\"].sla_met\n",
    "} for r in results])\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Communication\n",
    "\n",
    "Each incident generates tailored communications for technical teams, management, and affected users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = results[0]\n",
    "print(f\"Ticket: {sample['ticket_id']}\\n\")\n",
    "for comm in sample[\"response\"].communications:\n",
    "    print(f\"--- {comm.audience.upper()} ---\")\n",
    "    print(f\"Subject: {comm.subject}\")\n",
    "    print(f\"{comm.body[:300]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Open **Domino Experiment Manager** to view:\n",
    "- Execution flow across all 4 agents\n",
    "- Inline evaluation metrics per trace\n",
    "- Aggregated statistics across the batch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
