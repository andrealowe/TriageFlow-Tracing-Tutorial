{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TriageFlow: Incident Triage Demo\n",
    "\n",
    "Multi-agent incident triage with Domino GenAI tracing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Save your API key as a Domino user environment variable:\n",
    "1. **Account Settings** â†’ **User Environment Variables**\n",
    "2. Add `OPENAI_API_KEY` or `ANTHROPIC_API_KEY`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Provider\n",
    "\n",
    "Choose your LLM provider. Both use the same pipeline with provider-specific auto-tracing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0dbc6b2b2094589a7acc12ba68e42fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Provider:', options=('openai', 'anthropic'), value='openai')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "provider_dropdown = widgets.Dropdown(\n",
    "    options=[\"openai\", \"anthropic\"],\n",
    "    value=\"openai\",\n",
    "    description=\"Provider:\"\n",
    ")\n",
    "display(provider_dropdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Configuration\n",
    "\n",
    "All prompts, model settings, and agent parameters are centralized in `config.yaml`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provider: anthropic\n",
      "Model: claude-sonnet-4-20250514\n"
     ]
    }
   ],
   "source": [
    "with open(\"config.yaml\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "provider = provider_dropdown.value\n",
    "model = config[\"models\"][provider]\n",
    "print(f\"Provider: {provider}\\nModel: {model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Client & Auto-Tracing\n",
    "\n",
    "MLflow's `autolog()` automatically captures all LLM calls without additional instrumentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto-tracing enabled for anthropic\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "if provider == \"openai\":\n",
    "    from openai import OpenAI\n",
    "    client = OpenAI()\n",
    "    mlflow.openai.autolog()\n",
    "else:\n",
    "    from anthropic import Anthropic\n",
    "    client = Anthropic()\n",
    "    mlflow.anthropic.autolog()\n",
    "\n",
    "print(f\"Auto-tracing enabled for {provider}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Domino Tracing\n",
    "\n",
    "- `add_tracing`: Decorator for capturing inputs, outputs, and evaluation metrics\n",
    "- `DominoRun`: Context manager for aggregating metrics across multiple traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from domino.agents.tracing import add_tracing\n",
    "from domino.agents.logging import DominoRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Incident, IncidentSource\n",
    "from agents import classify_incident, assess_impact, match_resources, draft_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Inline Evaluators\n",
    "\n",
    "Evaluators run automatically after each agent call, computing quality metrics from inputs and outputs. Results are attached directly to the trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def classifier_evaluator(span) -> dict:\n    \"\"\"Check if urgency aligns with critical keywords.\"\"\"\n    inputs = span.inputs or {}\n    outputs = span.outputs\n    # Handle Pydantic model output\n    if hasattr(outputs, \"model_dump\"):\n        outputs = outputs.model_dump()\n    outputs = outputs or {}\n    \n    urgency = outputs.get(\"urgency\", 3)\n    confidence = outputs.get(\"confidence\", 0.5)\n    description = str(inputs.get(\"incident\", {}).get(\"description\", \"\")).lower()\n    critical_keywords = [\"breach\", \"outage\", \"critical\", \"emergency\", \"down\", \"compromised\"]\n    has_critical = any(kw in description for kw in critical_keywords)\n    urgency_appropriate = \"appropriate\" if (has_critical and urgency >= 4) or (not has_critical and urgency < 4) else \"misaligned\"\n    return {\n        \"classification_confidence\": confidence,\n        \"urgency_appropriate\": urgency_appropriate,\n        \"category_assigned\": outputs.get(\"category\", \"unknown\")\n    }"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def impact_evaluator(span) -> dict:\n    \"\"\"Verify impact score correlates with urgency.\"\"\"\n    inputs = span.inputs or {}\n    outputs = span.outputs\n    if hasattr(outputs, \"model_dump\"):\n        outputs = outputs.model_dump()\n    outputs = outputs or {}\n    \n    impact_score = outputs.get(\"impact_score\", 5.0)\n    classification = inputs.get(\"classification\", {})\n    if hasattr(classification, \"model_dump\"):\n        classification = classification.model_dump()\n    urgency = classification.get(\"urgency\", 3) if isinstance(classification, dict) else 3\n    similar_count = len(outputs.get(\"similar_incidents\", []))\n    impact_urgency_aligned = abs(impact_score / 2 - urgency) <= 1.5\n    return {\n        \"impact_score\": impact_score,\n        \"historical_matches_found\": similar_count,\n        \"impact_urgency_alignment\": \"aligned\" if impact_urgency_aligned else \"misaligned\",\n        \"blast_radius\": outputs.get(\"blast_radius\", \"unknown\")\n    }"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def resource_evaluator(span) -> dict:\n    \"\"\"Evaluate resource match quality and SLA compliance.\"\"\"\n    outputs = span.outputs\n    if hasattr(outputs, \"model_dump\"):\n        outputs = outputs.model_dump()\n    outputs = outputs or {}\n    \n    primary = outputs.get(\"primary_responder\", {})\n    if hasattr(primary, \"model_dump\"):\n        primary = primary.model_dump()\n    match_score = primary.get(\"match_score\", 0.5) if isinstance(primary, dict) else 0.5\n    sla_met = outputs.get(\"sla_met\", False)\n    backups = outputs.get(\"backup_responders\", [])\n    return {\n        \"resource_match_score\": match_score,\n        \"sla_compliance\": \"met\" if sla_met else \"at_risk\",\n        \"backup_count\": len(backups) if isinstance(backups, list) else 0\n    }"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def response_evaluator(span) -> dict:\n    \"\"\"Assess response plan completeness.\"\"\"\n    outputs = span.outputs\n    if hasattr(outputs, \"model_dump\"):\n        outputs = outputs.model_dump()\n    outputs = outputs or {}\n    \n    communications = outputs.get(\"communications\", [])\n    action_items = outputs.get(\"action_items\", [])\n    completeness = outputs.get(\"completeness_score\", 0.5)\n    return {\n        \"completeness_score\": completeness,\n        \"communication_count\": len(communications) if isinstance(communications, list) else 0,\n        \"action_item_count\": len(action_items) if isinstance(action_items, list) else 0\n    }"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Traced Pipeline Functions\n",
    "\n",
    "The `@add_tracing` decorator wraps each agent call, capturing:\n",
    "- Function inputs and outputs\n",
    "- Nested LLM calls (via `autolog_frameworks`)\n",
    "- Evaluation metrics (via `evaluator`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "framework = [provider]\n",
    "\n",
    "@add_tracing(name=\"classify_incident\", autolog_frameworks=framework, evaluator=classifier_evaluator)\n",
    "def traced_classify(incident: Incident):\n",
    "    return classify_incident(client, provider, model, incident, config)\n",
    "\n",
    "@add_tracing(name=\"assess_impact\", autolog_frameworks=framework, evaluator=impact_evaluator)\n",
    "def traced_assess(incident, classification):\n",
    "    return assess_impact(client, provider, model, incident, classification, config)\n",
    "\n",
    "@add_tracing(name=\"match_resources\", autolog_frameworks=framework, evaluator=resource_evaluator)\n",
    "def traced_match(classification, impact):\n",
    "    return match_resources(client, provider, model, classification, impact, config)\n",
    "\n",
    "@add_tracing(name=\"draft_response\", autolog_frameworks=framework, evaluator=response_evaluator)\n",
    "def traced_draft(incident, classification, impact, resources):\n",
    "    return draft_response(client, provider, model, incident, classification, impact, resources, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Sample Incidents\n",
    "\n",
    "Eight incidents spanning financial services, healthcare, energy, and public sector verticals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticket_id</th>\n",
       "      <th>description</th>\n",
       "      <th>source</th>\n",
       "      <th>reporter</th>\n",
       "      <th>affected_system</th>\n",
       "      <th>initial_severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INC-2024-2001</td>\n",
       "      <td>Multiple users reporting inability to access t...</td>\n",
       "      <td>user_report</td>\n",
       "      <td>Help Desk</td>\n",
       "      <td>Trading Platform</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INC-2024-2002</td>\n",
       "      <td>Automated security scan detected unusual outbo...</td>\n",
       "      <td>automated_scan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DB-PROD-03</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INC-2024-2003</td>\n",
       "      <td>Monthly compliance report generation failed. E...</td>\n",
       "      <td>monitoring</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Compliance Reporting System</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INC-2024-2004</td>\n",
       "      <td>User john.smith@company.com unable to reset pa...</td>\n",
       "      <td>user_report</td>\n",
       "      <td>john.smith@company.com</td>\n",
       "      <td>Identity Management</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INC-2024-2005</td>\n",
       "      <td>Patient data synchronization between EMR and b...</td>\n",
       "      <td>monitoring</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EMR-Billing Integration</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>INC-2024-2006</td>\n",
       "      <td>SCADA monitoring system showing intermittent c...</td>\n",
       "      <td>monitoring</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SCADA Control System</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>INC-2024-2007</td>\n",
       "      <td>Citizen services portal experiencing slow resp...</td>\n",
       "      <td>user_report</td>\n",
       "      <td>Social Media Team</td>\n",
       "      <td>Citizen Portal</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>INC-2024-2008</td>\n",
       "      <td>Database replication lag detected between prim...</td>\n",
       "      <td>monitoring</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Database Cluster</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ticket_id                                        description  \\\n",
       "0  INC-2024-2001  Multiple users reporting inability to access t...   \n",
       "1  INC-2024-2002  Automated security scan detected unusual outbo...   \n",
       "2  INC-2024-2003  Monthly compliance report generation failed. E...   \n",
       "3  INC-2024-2004  User john.smith@company.com unable to reset pa...   \n",
       "4  INC-2024-2005  Patient data synchronization between EMR and b...   \n",
       "5  INC-2024-2006  SCADA monitoring system showing intermittent c...   \n",
       "6  INC-2024-2007  Citizen services portal experiencing slow resp...   \n",
       "7  INC-2024-2008  Database replication lag detected between prim...   \n",
       "\n",
       "           source                reporter              affected_system  \\\n",
       "0     user_report               Help Desk             Trading Platform   \n",
       "1  automated_scan                     NaN                   DB-PROD-03   \n",
       "2      monitoring                     NaN  Compliance Reporting System   \n",
       "3     user_report  john.smith@company.com          Identity Management   \n",
       "4      monitoring                     NaN      EMR-Billing Integration   \n",
       "5      monitoring                     NaN         SCADA Control System   \n",
       "6     user_report       Social Media Team               Citizen Portal   \n",
       "7      monitoring                     NaN             Database Cluster   \n",
       "\n",
       "   initial_severity  \n",
       "0                 4  \n",
       "1                 5  \n",
       "2                 3  \n",
       "3                 2  \n",
       "4                 4  \n",
       "5                 5  \n",
       "6                 3  \n",
       "7                 4  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"example-data/sample_incidents.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8 incidents\n"
     ]
    }
   ],
   "source": [
    "def row_to_incident(row) -> Incident:\n",
    "    return Incident(\n",
    "        ticket_id=row[\"ticket_id\"],\n",
    "        description=row[\"description\"],\n",
    "        source=IncidentSource(row[\"source\"]),\n",
    "        reporter=row[\"reporter\"] if pd.notna(row[\"reporter\"]) else None,\n",
    "        affected_system=row[\"affected_system\"] if pd.notna(row[\"affected_system\"]) else None,\n",
    "        initial_severity=int(row[\"initial_severity\"]) if pd.notna(row[\"initial_severity\"]) else None\n",
    "    )\n",
    "\n",
    "incidents = [row_to_incident(row) for _, row in df.iterrows()]\n",
    "print(f\"Loaded {len(incidents)} incidents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Triage Pipeline\n",
    "\n",
    "`DominoRun` aggregates metrics across all traces in the batch via `custom_summary_metrics`. Supported aggregations: `mean`, `median`, `stdev`, `min`, `max`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_metrics = [\n",
    "    (\"classification_confidence\", \"mean\"),\n",
    "    (\"classification_confidence\", \"stdev\"),\n",
    "    (\"impact_score\", \"median\"),\n",
    "    (\"impact_score\", \"max\"),\n",
    "    (\"resource_match_score\", \"mean\"),\n",
    "    (\"completeness_score\", \"mean\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Failed to read agent config yaml at path ./agent_config.yaml: [Errno 2] No such file or directory: './agent_config.yaml'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing INC-2024-2001...\n",
      "ðŸƒ View run clean-lamb-343 at: http://127.0.0.1:8768/#/experiments/1993/runs/f321557caeb54f568265455be6db24ad\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:8768/#/experiments/1993\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m incident \u001b[38;5;129;01min\u001b[39;00m incidents:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mincident\u001b[38;5;241m.\u001b[39mticket_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m     classification \u001b[38;5;241m=\u001b[39m \u001b[43mtraced_classify\u001b[49m\u001b[43m(\u001b[49m\u001b[43mincident\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     impact \u001b[38;5;241m=\u001b[39m traced_assess(incident, classification)\n\u001b[1;32m      9\u001b[0m     resources \u001b[38;5;241m=\u001b[39m traced_match(classification, impact)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/domino/agents/tracing/tracing.py:252\u001b[0m, in \u001b[0;36madd_tracing.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mlflow\u001b[38;5;241m.\u001b[39mstart_span(name) \u001b[38;5;28;01mas\u001b[39;00m parent_span:\n\u001b[1;32m    250\u001b[0m     _set_span_inputs(parent_span, func, args, kwargs)\n\u001b[0;32m--> 252\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m     parent_span\u001b[38;5;241m.\u001b[39mset_outputs(result)\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;241m!=\u001b[39m DOMINO_NO_RESULT_ADD_TRACING:\n",
      "Cell \u001b[0;32mIn[27], line 5\u001b[0m, in \u001b[0;36mtraced_classify\u001b[0;34m(incident)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;129m@add_tracing\u001b[39m(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassify_incident\u001b[39m\u001b[38;5;124m\"\u001b[39m, autolog_frameworks\u001b[38;5;241m=\u001b[39mframework, evaluator\u001b[38;5;241m=\u001b[39mclassifier_evaluator)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtraced_classify\u001b[39m(incident: Incident):\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mclassify_incident\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprovider\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mincident\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/code/agents.py:53\u001b[0m, in \u001b[0;36mclassify_incident\u001b[0;34m(client, provider, model, incident, config)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[0;32m/mnt/code/agents.py:39\u001b[0m, in \u001b[0;36mparse_json_response\u001b[0;34m(response)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mconfig_to_anthropic_tools\u001b[39m(tool_configs: \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[1;32m     36\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert config tool schemas to Anthropic format.\"\"\"\u001b[39;00m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [{\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: t[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m---> 39\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m\"\u001b[39m: t[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_schema\u001b[39m\u001b[38;5;124m\"\u001b[39m: t[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameters\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     41\u001b[0m     } \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tool_configs]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://127.0.0.1:8768/static-files/lib/notebook-trace-renderer/index.html?trace_id=tr-fd1edc73c9476db8d32de0e97aee8e65&amp;experiment_id=1993&amp;version=3.2.0\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "Trace(trace_id=tr-fd1edc73c9476db8d32de0e97aee8e65)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "with DominoRun(custom_summary_metrics=aggregated_metrics) as run:\n",
    "    for incident in incidents:\n",
    "        print(f\"Processing {incident.ticket_id}...\")\n",
    "        \n",
    "        classification = traced_classify(incident)\n",
    "        impact = traced_assess(incident, classification)\n",
    "        resources = traced_match(classification, impact)\n",
    "        response = traced_draft(incident, classification, impact, resources)\n",
    "        \n",
    "        results.append({\n",
    "            \"ticket_id\": incident.ticket_id,\n",
    "            \"classification\": classification,\n",
    "            \"impact\": impact,\n",
    "            \"resources\": resources,\n",
    "            \"response\": response\n",
    "        })\n",
    "        print(f\"  â†’ {classification.category.value} | Urgency: {classification.urgency} | Impact: {impact.impact_score}\")\n",
    "\n",
    "print(f\"\\nProcessed {len(results)} incidents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame([{\n",
    "    \"Ticket\": r[\"ticket_id\"],\n",
    "    \"Category\": r[\"classification\"].category.value,\n",
    "    \"Urgency\": r[\"classification\"].urgency,\n",
    "    \"Impact\": r[\"impact\"].impact_score,\n",
    "    \"Responder\": r[\"resources\"].primary_responder.name,\n",
    "    \"SLA Met\": r[\"resources\"].sla_met\n",
    "} for r in results])\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Communication\n",
    "\n",
    "Each incident generates tailored communications for technical teams, management, and affected users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = results[0]\n",
    "print(f\"Ticket: {sample['ticket_id']}\\n\")\n",
    "for comm in sample[\"response\"].communications:\n",
    "    print(f\"--- {comm.audience.upper()} ---\")\n",
    "    print(f\"Subject: {comm.subject}\")\n",
    "    print(f\"{comm.body[:300]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Open **Domino Experiment Manager** to view:\n",
    "- Execution flow across all 4 agents\n",
    "- Inline evaluation metrics per trace\n",
    "- Aggregated statistics across the batch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}